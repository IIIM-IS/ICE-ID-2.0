"""
Core type definitions for the ER benchmark framework.

These types provide a common vocabulary across all components:
datasets, models, blocking, calibration, clustering, and metrics.
"""

from dataclasses import dataclass, field
from typing import Dict, List, Any, Tuple, Optional, Union, Set
import pandas as pd
import numpy as np


Record = Dict[str, Any]

Pair = Tuple[int, int]

ScoredPair = Tuple[Pair, float]

ClusterLabels = Dict[int, int]


@dataclass
class DatasetSplit:
    """
    A train/val/test split of entity resolution data.
    
    Supports both two-table ER (left_table, right_table) and 
    single-table deduplication (records only).
    
    Attributes:
        name: Dataset identifier.
        records: All records for dedup tasks (keyed by id).
        left_table: Left table for two-table ER.
        right_table: Right table for two-table ER.
        train_pairs: Labeled pairs for training [(id1, id2, label), ...].
        val_pairs: Labeled pairs for validation.
        test_pairs: Labeled pairs for testing.
        cluster_labels: Ground truth entity clusters {record_id: cluster_id}.
        metadata: Additional dataset-specific information.
    """
    name: str
    records: Optional[pd.DataFrame] = None
    left_table: Optional[pd.DataFrame] = None
    right_table: Optional[pd.DataFrame] = None
    train_pairs: Optional[pd.DataFrame] = None
    val_pairs: Optional[pd.DataFrame] = None
    test_pairs: Optional[pd.DataFrame] = None
    cluster_labels: Optional[Dict[int, int]] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    @property
    def is_two_table(self) -> bool:
        """Returns True if this is a two-table ER task."""
        return self.left_table is not None and self.right_table is not None
    
    @property
    def is_dedup(self) -> bool:
        """Returns True if this is a deduplication task."""
        return self.records is not None and not self.is_two_table
    
    def get_all_records(self) -> pd.DataFrame:
        """Returns all records as a single DataFrame."""
        if self.is_two_table:
            left = self.left_table.copy()
            right = self.right_table.copy()
            left["_table"] = "left"
            right["_table"] = "right"
            return pd.concat([left, right], ignore_index=True)
        return self.records
    
    def get_record_by_id(self, record_id: int) -> Optional[Record]:
        """Retrieve a single record by ID."""
        if self.is_two_table:
            for table in [self.left_table, self.right_table]:
                match = table[table["id"] == record_id]
                if len(match) > 0:
                    return match.iloc[0].to_dict()
        elif self.records is not None:
            match = self.records[self.records["id"] == record_id]
            if len(match) > 0:
                return match.iloc[0].to_dict()
        return None


@dataclass
class CandidatePairs:
    """
    Candidate pairs generated by a blocking strategy.
    
    Attributes:
        pairs: List of (id1, id2) candidate pairs.
        scores: Optional similarity scores for each pair.
        metadata: Blocking statistics (reduction ratio, etc.).
    """
    pairs: List[Pair]
    scores: Optional[List[float]] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __len__(self) -> int:
        return len(self.pairs)
    
    def to_dataframe(self) -> pd.DataFrame:
        """Convert to DataFrame with id1, id2, score columns."""
        df = pd.DataFrame(self.pairs, columns=["id1", "id2"])
        if self.scores is not None:
            df["score"] = self.scores
        return df


@dataclass
class PredictionResult:
    """
    Model predictions on candidate pairs.
    
    Attributes:
        pairs: The pairs that were scored.
        scores: Model confidence scores [0, 1].
        predictions: Binary predictions after thresholding.
        threshold: The threshold used for predictions.
    """
    pairs: List[Pair]
    scores: np.ndarray
    predictions: Optional[np.ndarray] = None
    threshold: float = 0.5
    
    def get_positive_pairs(self) -> List[Pair]:
        """Returns pairs predicted as matches."""
        if self.predictions is None:
            preds = (self.scores >= self.threshold).astype(int)
        else:
            preds = self.predictions
        return [p for p, pred in zip(self.pairs, preds) if pred == 1]
    
    def to_dataframe(self) -> pd.DataFrame:
        """Convert to DataFrame."""
        df = pd.DataFrame(self.pairs, columns=["id1", "id2"])
        df["score"] = self.scores
        if self.predictions is not None:
            df["prediction"] = self.predictions
        return df


@dataclass 
class ClusterResult:
    """
    Clustering output.
    
    Attributes:
        clusters: List of clusters, each cluster is a list of record IDs.
        labels: Mapping from record_id to cluster_id.
    """
    clusters: List[List[int]]
    labels: Dict[int, int] = field(default_factory=dict)
    
    def __post_init__(self):
        if not self.labels and self.clusters:
            for cluster_id, members in enumerate(self.clusters):
                for record_id in members:
                    self.labels[record_id] = cluster_id
    
    @property
    def n_clusters(self) -> int:
        return len(self.clusters)
    
    @property
    def n_singletons(self) -> int:
        return sum(1 for c in self.clusters if len(c) == 1)


@dataclass
class EvaluationResult:
    """
    Evaluation metrics result.
    
    Attributes:
        pairwise: Pairwise metrics (precision, recall, F1, AUC).
        clustering: Clustering metrics (ARI, B3).
        ranking: Ranking metrics (P@k, R@k).
        sanity_checks: Sanity check results.
        metadata: Additional information.
    """
    pairwise: Dict[str, float] = field(default_factory=dict)
    clustering: Dict[str, float] = field(default_factory=dict)
    ranking: Dict[str, float] = field(default_factory=dict)
    sanity_checks: Dict[str, bool] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """Flatten all metrics to a single dict."""
        result = {}
        for prefix, metrics in [
            ("pairwise", self.pairwise),
            ("clustering", self.clustering),
            ("ranking", self.ranking),
        ]:
            for k, v in metrics.items():
                result[f"{prefix}_{k}"] = v
        result["sanity_checks"] = self.sanity_checks
        result.update(self.metadata)
        return result

