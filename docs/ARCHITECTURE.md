# ICE-ID Project Architecture

Complete map of every file and folder in the ICE-ID project, explaining what each component does and how they relate to each other.

---

## ğŸ“‹ Table of Contents

- [Top-Level Structure](#top-level-structure)
- [Benchmarking Framework](#bench-benchmarking-framework)
- [Dashboard](#dashboard-interactive-web-dashboard)
- [Papers](#papers-latex-papers)
- [Data Storage](#data-data-storage)
- [Data Flow Overview](#data-flow-overview)
- [Module Dependencies](#module-dependencies)
- [Key Design Patterns](#key-design-patterns)

---

## Top-Level Structure

```
ICE-ID-2.0/
â”œâ”€â”€ bench/                  # Main benchmarking framework
â”œâ”€â”€ dashboard/              # Interactive web dashboard (Streamlit)
â”œâ”€â”€ data/                   # Data storage (runs, versions, external)
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ papers/                 # LaTeX papers and figures
â”œâ”€â”€ raw_data/               # Source ICE-ID dataset files
â”œâ”€â”€ runs/                   # Experiment run outputs
â”œâ”€â”€ README.md               # Project overview
â”œâ”€â”€ QUICK_START.md          # Getting started guide
â””â”€â”€ requirements.txt        # Python dependencies
```

---

## `/bench/` â€” Benchmarking Framework

The core entity resolution benchmarking system. This is the primary codebase for running experiments.

### `/bench/bench/` â€” Python Package

```
bench/bench/
â”œâ”€â”€ __init__.py             # Package initialization
â”œâ”€â”€ cli.py                  # Command-line interface entry point
â”‚
â”œâ”€â”€ core/                   # Core types and utilities
â”‚   â”œâ”€â”€ types.py            # DatasetSplit, Pair, Record, ClusterResult, etc.
â”‚   â”œâ”€â”€ registry.py         # Plugin registry for models, datasets, blockers
â”‚   â””â”€â”€ random.py           # Reproducible random seed management
â”‚
â”œâ”€â”€ data/                   # Dataset providers
â”‚   â”œâ”€â”€ base.py             # BaseDataset abstract class
â”‚   â”œâ”€â”€ iceid.py            # ICE-ID dataset loader with temporal splits
â”‚   â”œâ”€â”€ deepmatcher.py      # DeepMatcher datasets (Abt-Buy, DBLP-ACM, etc.)
â”‚   â”œâ”€â”€ zenodo.py           # Zenodo-hosted datasets
â”‚   â”œâ”€â”€ wdc_products.py      # WDC Products dataset
â”‚   â”œâ”€â”€ additional_datasets.py  # FEBRL, Synthea, etc.
â”‚   â””â”€â”€ external_profiles.py    # Profiling utilities for external datasets
â”‚
â”œâ”€â”€ blocking/               # Candidate generation strategies
â”‚   â”œâ”€â”€ base.py             # BaseBlocker abstract class
â”‚   â”œâ”€â”€ token_blocking.py   # Token-based blocking (field tokenization)
â”‚   â”œâ”€â”€ phonetic_blocking.py # Soundex/Metaphone blocking
â”‚   â””â”€â”€ geo_hierarchy.py    # Geographic hierarchy blocking
â”‚
â”œâ”€â”€ models/                 # Entity resolution models
â”‚   â”œâ”€â”€ base.py             # BaseModel abstract class (fit, score, predict)
â”‚   â”œâ”€â”€ nars.py             # NARS (Non-Axiomatic Reasoning System)
â”‚   â”œâ”€â”€ fellegi_sunter.py   # Fellegi-Sunter probabilistic linkage
â”‚   â”œâ”€â”€ rules.py            # Rule-based deterministic matcher
â”‚   â”œâ”€â”€ ensemble.py         # ML ensemble models (XGBoost, LightGBM, RandomForest, GradientBoosting)
â”‚   â”œâ”€â”€ ditto_adapter.py    # Ditto deep learning model adapter
â”‚   â”œâ”€â”€ hiergat_adapter.py  # HierGAT graph attention network adapter
â”‚   â”œâ”€â”€ zeroer_adapter.py   # ZeroER unsupervised matcher adapter
â”‚   â”œâ”€â”€ anymatch_adapter.py # AnyMatch zero-shot adapter
â”‚   â”œâ”€â”€ matchgpt_adapter.py # MatchGPT LLM-based matcher adapter
â”‚   â””â”€â”€ opennars_adapter.py # OpenNARS-for-Applications adapter
â”‚
â”œâ”€â”€ calibration/            # Score calibration methods
â”‚   â”œâ”€â”€ base.py             # BaseCalibrator abstract class
â”‚   â”œâ”€â”€ fixed_threshold.py  # Fixed threshold calibration
â”‚   â”œâ”€â”€ platt.py            # Platt scaling (sigmoid fit)
â”‚   â””â”€â”€ isotonic.py         # Isotonic regression calibration
â”‚
â”œâ”€â”€ clustering/             # Entity clustering algorithms
â”‚   â”œâ”€â”€ base.py             # BaseClusterer abstract class
â”‚   â”œâ”€â”€ connected_components.py  # Graph connected components
â”‚   â””â”€â”€ hac.py              # Hierarchical agglomerative clustering
â”‚
â”œâ”€â”€ metrics/                # Evaluation metrics
â”‚   â”œâ”€â”€ pairwise.py         # Precision, Recall, F1, AUC, AP
â”‚   â”œâ”€â”€ ranking.py          # P@k, R@k
â”‚   â”œâ”€â”€ clustering.py      # ARI, BÂ³ F1
â”‚   â””â”€â”€ sanity.py           # Sanity checks (random baseline comparison)
â”‚
â”œâ”€â”€ runner/                 # Experiment execution
â”‚   â”œâ”€â”€ run_one.py          # Single experiment runner
â”‚   â””â”€â”€ run_grid.py         # Grid search over configurations
â”‚
â”œâ”€â”€ config/                 # Configuration schemas
â”‚   â”œâ”€â”€ schema.py           # Pydantic config validation
â”‚   â””â”€â”€ examples/           # Example YAML configs
â”‚       â”œâ”€â”€ iceid_nars.yaml
â”‚       â”œâ”€â”€ iceid_fellegi_sunter.yaml
â”‚       â””â”€â”€ zenodo_nars.yaml
â”‚
â””â”€â”€ pairs/                  # (Reserved for pair builders)
```

### `/bench/scripts/` â€” Executable Scripts

```
bench/scripts/
â”œâ”€â”€ run_experiments.py      # Main experiment runner with subcommands
â”œâ”€â”€ run_nars_full_eval.py   # NARS evaluation across all datasets
â”œâ”€â”€ generate_paper_artifacts.py  # Generate figures/tables for papers
â”œâ”€â”€ prepare_data.py         # Data preparation and download
â””â”€â”€ fetch_external_datasets.py   # Download FEBRL, Synthea, ORCID, etc.
```

### `/bench/benchmark_results/` â€” Experiment Outputs

```
bench/benchmark_results/
â”œâ”€â”€ nars_full_eval.csv      # NARS results on all datasets (Table 6)
â”œâ”€â”€ nars_ablations.csv      # NARS ablation study results
â”œâ”€â”€ nars_calibration_sensitivity.csv  # Calibration strategy comparison
â”œâ”€â”€ nars_graph_eval.csv     # End-to-end graph evaluation
â”œâ”€â”€ ditto_results.csv       # Ditto model results
â”œâ”€â”€ hiergat_results.csv     # HierGAT model results
â”œâ”€â”€ zeroer_results.csv      # ZeroER model results
â”œâ”€â”€ anymatch_results.csv    # AnyMatch model results
â””â”€â”€ FULL_BENCHMARK_REPORT.md # Summary report
```

### `/bench/paper_artifacts/` â€” Paper-Ready Data

```
bench/paper_artifacts/
â”œâ”€â”€ plot_data/              # JSON/CSV for figures
â”‚   â”œâ”€â”€ fig1_temporal_coverage.json
â”‚   â”œâ”€â”€ fig2_missingness.json
â”‚   â”œâ”€â”€ fig3_cluster_sizes.json
â”‚   â”œâ”€â”€ fig4_ambiguity.json
â”‚   â”œâ”€â”€ fig5_blocking.json
â”‚   â”œâ”€â”€ calibration_sensitivity.json
â”‚   â””â”€â”€ nars_rerun_f1.json
â”‚
â”œâ”€â”€ table_data/             # JSON/CSV for tables
â”‚   â”œâ”€â”€ table1_dataset_synopsis.csv
â”‚   â”œâ”€â”€ table2_schema_matrix.csv
â”‚   â”œâ”€â”€ table3_protocols_splits.csv
â”‚   â”œâ”€â”€ table_longitudinal_comparison.json
â”‚   â””â”€â”€ table_external_datasets.json
â”‚
â”œâ”€â”€ nars_full_eval.json     # NARS results (JSON format)
â”œâ”€â”€ nars_graph_eval.json    # Graph evaluation results
â””â”€â”€ nars_calibration_sensitivity.json
```

### `/bench/deepmatcher_data/` â€” Classic ER Datasets

```
bench/deepmatcher_data/
â”œâ”€â”€ abt_buy/                # Abt-Buy product matching
â”œâ”€â”€ amazon_google/         # Amazon-Google product matching
â”œâ”€â”€ dblp_acm/               # DBLP-ACM citation matching
â”œâ”€â”€ dblp_scholar/           # DBLP-Google Scholar citation matching
â”œâ”€â”€ itunes_amazon/          # iTunes-Amazon music matching
â”œâ”€â”€ walmart_amazon/         # Walmart-Amazon product matching
â”œâ”€â”€ beer/                   # BeerAdvocate-RateBeer matching
â””â”€â”€ fodors_zagats/          # Fodors-Zagats restaurant matching
```

Each dataset folder contains:
- `tableA.csv`, `tableB.csv` â€” Source tables
- `train.csv`, `valid.csv`, `test.csv` â€” Labeled pairs

### `/bench/external/` â€” External Model Repositories

```
bench/external/
â”œâ”€â”€ ditto/                  # Ditto deep learning model (cloned repo)
â”œâ”€â”€ zeroer/                 # ZeroER unsupervised model
â”œâ”€â”€ anymatch/               # AnyMatch zero-shot model
â”œâ”€â”€ MatchGPT/               # MatchGPT LLM-based model
â”œâ”€â”€ OpenNARS-for-Applications/  # OpenNARS C implementation
â”œâ”€â”€ wdcproducts/             # WDC Products dataset tools
â”œâ”€â”€ requirements_external.txt   # Dependencies for external models
â””â”€â”€ setup_external.sh       # Setup script for external repos
```

---

## `/dashboard/` â€” Interactive Web Dashboard

A Streamlit-based dashboard for interactive exploration and evaluation.

```
dashboard/
â”œâ”€â”€ app.py                  # Main Streamlit application entry
â”œâ”€â”€ backends.py             # Backend service connections
â”œâ”€â”€ er_bench.py             # Benchmark interface
â”œâ”€â”€ eval_api.py             # Evaluation API endpoints
â”œâ”€â”€ train_api.py            # Training API endpoints
â”œâ”€â”€ graphing.py             # Visualization utilities
â”œâ”€â”€ inspector_tab.py        # Data inspection UI
â”œâ”€â”€ model_registry.py       # Model management
â”œâ”€â”€ settings_manager.py     # Configuration management
â”œâ”€â”€ schemas.py              # Data schemas
â”œâ”€â”€ ds_io.py                # Dataset I/O utilities
â”œâ”€â”€ edits.py                # Data editing utilities
â”œâ”€â”€ external_models.py      # External model integration
â”‚
â”œâ”€â”€ blocking/               # Blocking UI components
â”œâ”€â”€ calibration/            # Calibration UI components
â”œâ”€â”€ clustering/             # Clustering UI components
â”œâ”€â”€ datasets/               # Dataset UI components
â”œâ”€â”€ metrics/                # Metrics display components
â”œâ”€â”€ models/                 # Model UI components
â””â”€â”€ tests/                  # Dashboard tests
```

---

## `/papers/` â€” LaTeX Papers

```
papers/
â”œâ”€â”€ main_data_paper.tex     # Dataset paper (ICE-ID description)
â”œâ”€â”€ main_nars_paper.tex     # Methods paper (NARS evaluation)
â”œâ”€â”€ main.bib                # BibTeX references
â”œâ”€â”€ neurips_2024.sty        # NeurIPS style file
â”œâ”€â”€ notes.txt               # Author notes
â”‚
â”œâ”€â”€ figures/                # Generated figures
â”‚   â”œâ”€â”€ fig1_temporal_coverage.pdf
â”‚   â”œâ”€â”€ fig2_missingness.pdf
â”‚   â”œâ”€â”€ fig3_cluster_sizes.pdf
â”‚   â”œâ”€â”€ fig4_ambiguity.pdf
â”‚   â”œâ”€â”€ fig5_blocking.pdf
â”‚   â”œâ”€â”€ nars_rerun_f1.pdf
â”‚   â”œâ”€â”€ calibration_sensitivity.png
â”‚   â”œâ”€â”€ cross_dataset_heatmap.png
â”‚   â”œâ”€â”€ ablation_chart.png
â”‚   â””â”€â”€ missingno_iceid.pdf
â”‚
â””â”€â”€ *.pdf                   # Compiled papers
```

---

## `/raw_data/` â€” ICE-ID Source Data

The original Icelandic census data files:

```
raw_data/
â”œâ”€â”€ people.csv              # 984,028 census records (main table)
â”œâ”€â”€ counties.csv            # County geographic hierarchy
â”œâ”€â”€ districts.csv           # District geographic hierarchy
â”œâ”€â”€ parishes.csv            # Parish geographic hierarchy
â””â”€â”€ manntol_einstaklingar_new.csv  # Expert-curated person labels
```

### Key Fields in `people.csv`:

| Field | Description |
|-------|-------------|
| `id` | Unique record identifier |
| `person` | Cluster label (same person across censuses) |
| `heimild` | Census year (1703, 1801, ..., 1920) |
| `nafn_norm` | Normalized full name |
| `first_name`, `patronym`, `surname` | Name components |
| `birthyear`, `sex`, `marriagestatus` | Demographics |
| `farm`, `parish`, `district`, `county` | 4-level geography |
| `partner`, `father`, `mother` | Kinship links |

---

## `/data/` â€” Data Storage

```
data/
â”œâ”€â”€ raw_data/               # Symlink or copy of /raw_data/
â”œâ”€â”€ runs/                   # Dashboard experiment runs
â”œâ”€â”€ versions/               # Dataset versioning
â””â”€â”€ external_datasets/      # Downloaded external datasets
    â”œâ”€â”€ febrl/              # FEBRL synthetic data
    â”œâ”€â”€ synthea/            # Synthea synthetic patients
    â”œâ”€â”€ orcid/              # ORCID researcher data
    â”œâ”€â”€ semparl/            # SemParl parliamentary data
    â”œâ”€â”€ ckcc/               # CKCC correspondence data
    â””â”€â”€ correspsearch/      # correspSearch correspondence
```

---

## `/runs/` â€” Experiment Outputs

```
runs/
â”œâ”€â”€ er_bench_full/          # Full benchmark runs
â”œâ”€â”€ external_models/        # External model evaluation results
â”œâ”€â”€ test_all_models/        # Comprehensive model tests
â”œâ”€â”€ test_single/            # Single-model test runs
â”œâ”€â”€ hundred_loose_dual/     # Specific experiment configurations
â””â”€â”€ settings/               # Saved experiment settings
```

---

## Data Flow Overview

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   raw_data/  â”‚
                    â”‚  people.csv  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  bench/bench/data/    â”‚
               â”‚  iceid.py loads data  â”‚
               â”‚  + temporal splits    â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼              â–¼              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ blocking â”‚   â”‚  models  â”‚   â”‚ metrics  â”‚
     â”‚  tokens  â”‚   â”‚   NARS   â”‚   â”‚   F1     â”‚
     â”‚   geo    â”‚   â”‚  Ditto   â”‚   â”‚   ARI    â”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚              â”‚              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  scripts/run_*.py     â”‚
               â”‚  Execute experiments  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  benchmark_results/   â”‚
               â”‚  CSV/JSON outputs     â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  paper_artifacts/     â”‚
               â”‚  Figures & Tables     â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  papers/*.tex         â”‚
               â”‚  LaTeX compilation    â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Module Dependencies

```
core/types.py          â† Used by everything
       â”‚
       â”œâ”€â”€ data/base.py â†’ iceid.py, deepmatcher.py, ...
       â”‚
       â”œâ”€â”€ blocking/base.py â†’ token_blocking.py, phonetic_blocking.py
       â”‚
       â”œâ”€â”€ models/base.py â†’ nars.py, fellegi_sunter.py, ditto_adapter.py
       â”‚
       â”œâ”€â”€ calibration/base.py â†’ platt.py, isotonic.py
       â”‚
       â”œâ”€â”€ clustering/base.py â†’ connected_components.py, hac.py
       â”‚
       â””â”€â”€ metrics/ â†’ pairwise.py, ranking.py, clustering.py
              â”‚
              â””â”€â”€ runner/run_one.py â†’ orchestrates all above
                     â”‚
                     â””â”€â”€ scripts/run_experiments.py â†’ CLI entry
```

---

## Key Design Patterns

### 1. Plugin Registry

All models, datasets, and blockers register themselves:

```python
from bench.core.registry import get_registry
get_registry("models").register("nars", NarsModel)
```

### 2. DatasetSplit Container

A unified container for both deduplication and two-table ER:

```python
@dataclass
class DatasetSplit:
    name: str
    records: Optional[pd.DataFrame]      # For dedup
    left_table: Optional[pd.DataFrame]   # For two-table
    right_table: Optional[pd.DataFrame]
    train_pairs: Optional[pd.DataFrame]
    val_pairs: Optional[pd.DataFrame]
    test_pairs: Optional[pd.DataFrame]
    cluster_labels: Optional[Dict[int, int]]
```

### 3. Temporal OOD Splits

ICE-ID uses strictly temporal splits to simulate real deployment:
- **Train**: pre-1870
- **Validation**: 1870â€“1890
- **Test**: 1891â€“1920

### 4. Artifact-Backed Reporting

All paper figures/tables are generated from JSON/CSV artifacts:
- Scripts write to `paper_artifacts/`
- LaTeX references these files
- Ensures reproducibility and consistency

---

## ğŸ“š Related Documentation

- [WORKFLOWS.md](WORKFLOWS.md) â€” Step-by-step workflows
- [BENCHMARK_GUIDE.md](BENCHMARK_GUIDE.md) â€” Detailed benchmarking guide
- [QUICK_START.md](../QUICK_START.md) â€” Getting started guide

---

**Questions?** Check the [workflows guide](WORKFLOWS.md) or open an issue on GitHub.
